---
title: "MAT 8444 Report - Time Series Analysis of Electricity Demand and Related Data"
author: "Duane Stanton"
date: "May 8, 2019"
output: pdf_document
---

```{r, echo=F}
# upfront code for code chunk behavior
knitr::opts_chunk$set(echo=F, fig.align="center", message=F, warning=F)
```

```{r}
# Plot setup
theme_ds2 <- function(base_size = 12.5){
  theme_bw(base_size = base_size) %+replace%
    theme(
      #line = element_line(color = "#000000"),
      #text = element_text(color = "#000000"),
      axis.title = element_text(color = "#000000", face = "plain"),
      axis.text = element_text(color="#000000", size = 11),
      axis.line = element_line(size = 0.5, linetype = 1, color = "#505050"),
      #axis.line.y = element_line(size = 0.5, linetype = 1, color = "#505050"),
      #legend.key = element_rect(color="#D2E2F9", fill = "#FFFFFF", linetype = 0),
      legend.title = element_text(size = 11.5, face = "plain"),
      legend.title.align = 0.5,
      legend.text = element_text(size = 11),
      legend.background = element_rect(size = 0.1, color = "#EAEAEA", fill = "#FFFFFF", linetype = 0),
      panel.grid = element_line(color = "#505050", linetype = 0, size = 0.5),
      #panel.grid.minor.x = element_line(size = 0.35),
      #panel.grid.minor.y = element_line(size = 0.35),
      panel.border = element_rect(color = "#EAEAEA", fill = NA),
      panel.background = element_rect(fill = "#FFFFFF"),
      #plot.title = element_text(color = "#000000"),
      plot.background = element_rect(color = NA, fill = "#FFFFFF"),
      #plot.title = element_text(hjust = 0, face = "plain"),
      plot.subtitle = element_text(hjust = 0, size = 12, face = "plain"),
      plot.caption=element_text(size=11, hjust=1, face="italic", color="black")
      #strip.text = element_text(size = 12),
      #strip.background = element_rect(fill = NA),
      )
}

color_set8 <- c("#00205B", "#13B5EA", "#079500", "#9ECC14", "#CDB87D", "#EEB31B", "#E27400", "#894600")
```

# Upfront Details

## Motivation and Data

In order to practice a variety of time series analyses on 'real-world' data, hourly electricity demand from the Energy Information Administration[^1] (EIA) was collected from the administration's site. Specific variables included per-hour **actual demand** (the variable of primary interest), per-hour net generation (with any differential coming from imported electricity), and per-hour forecast demand 24 hours in the future. Data was aggregated to the daily level to align with temperature data (discussed further down). Demand was analyzed for the New York ISO and ISO New England (Independent System Operators - organizations tasked with monitoring/coordinating/controlling the electrical grid for a defined region) between 5am, July 1, 2015 and 5am, February 18, 2019 - observations from 2019 were excluded from the modeling process, originally planned due to limits in the economic index data, but ultimately it was held out for evaluating short-term future model performance. 

The primary analysis focused on NYISO data, with a very similar modeling process applied to ISONE data for comparison.

[^1]: "Bulk download facility." *U.S. Energy Information Administration.* U.S. Electrical System Operating Data. https://www.eia.gov/opendata/bulkfiles.php. Accessed 25 February 2019. 

The secondary data source of most interest was summary data for daily mean temperature in degrees Fahrenheit across New York counties from the National Oceanic and Atmospheric Administration[^2] (NOAA), for the same time period as the EIA data - this data was then population-weighted within years based on data from the U.S. Census Bureau[^3] to calculate state-level temperature estimates (since I considered population density an important factor when trying to link location temperatures and electricty consumption, e.g. air conditioner use in the summer).  

While I initially planned to use similar data for all counties in the New England, limitations in the NOAA data prevented this. Specifically, county-specific temperature data was provided as measurements from specific weather stations located in a given county, and while each station had a unique identifier, there was no readily accessible key on the NOAA site or elsewhere indicating in which county a given station resided - this would mean either manually looking up the location of each station (as I did for New York data), or iteratively downloading data for a single county at a time, manually appending county labels for each data subset.

[^2]: "Climate Data Online Search." *NOAA - National Centers for Environmental Information.* https://www.ncdc.noaa.gov/cdo-web/search. Accessed 24 March 2019.

[^3]: "PEPAGESEX - Annual Estimates of the Resident Population for Selected Age Groups by Sex for the United States, States, Counties, and Puerto Rico Commonwealth and Municipios." *U.S. Census Bureau American FactFinder.* Accessed 16 March 2019 for years 2015, 2016, 2017 estimates.

A final secondary data source considered was a composite index of monthly state-level economic conditions from the Federal Reserve Bank of Philadelphia[^4], with 100 aligning with the annual mean of 2007 (considered the peak of the previous economic cycle). This 'coincident index' factored in "nonfarm payroll employment, average hours worked in manufacturing by production workers, the unemployment rate, and wage and salary disbursements deflated by the consumer price index (U.S. city average)"; these factors and "an underlying (latent) factor" are input to a system of five equations (one for each factor mentioned) and ultimately generate the index value. There are papers linked in the cited source, but it is not immediately obvious how exactly the equations/indices are structured and weighted.

[^4]: "State Coincident Indices." *Federal Reserve Bank of Philadelphia.* https://www.phil.frb.org/research-and-data/regional-economy/indexes/coincident/. Accessed 17 February 2019 ; data accessed from the "Revised Data" linked .xls file at upper-right on the page.

### Summary of Data Processing - missing data imputation approaches

Electricity data was aggregated (summed) to the daily level for most of the analyses, as the related temperature data was available at the daily level as well. Some secondary analyses futher aggregated electricity and temperature data to the monthly level, as the economic index data was avalable at the monthly level.

There were some cases of missing (`NA`) electricity data (117 hourly observations for ISONE demand, 127 for ISONE net generation, 195 for NYISO demand and 205 each for net generation and day-ahead demand forecast (plus 48 single-hour observations 'completely' missing from the dataset, 19 for 01-Jul-2018, 5 for 02-Jul-2018, 18 for 11-Nov-2018, and 6 for 12-Nov-2018); for context, ISONE data had 31,873 rows of hourly data, NYISO had 31,825 rows. For these, the following imputation scheme was applied:

* For actual demand missingness, first model-estimated 'day-ahead demand' from 24 hours prior (from the original dataset) was input; if this was also missing, then the mean of 24 hours prior and 24 hours in the future was input; if one of these but not the other was missing, the non-missing value was input. For cases of *still*-missing data, the 'past and future observations' approach was applied to 48 hours-apart data. Where '2 days out' data was still insufficient, I applied the `na.kalman()` function from the `imputeTS` package to apply Kalman smoothing (with `method="auto.arima"`) *except* for 11 and 12 Nov 2018 still-missing demand data, where this approach yielded a exceptionally low daily-aggregated demand valued - in that case I uses `imputeTS::na.ma()` for moving-average imputation, which aligned much better with the general (nearby) data structure.

* For forecasted demand or net generation missingness, the "24 hours-apart" and (if needed) "48 hours-apart" method described above was used.  

* Temperature data was calculated at the county level by taking the mean of all observations for a given date in that county for the daily mean temperature. If this daily mean was not available, then the mean of the daily high and the daily low was used instead. This second method seemed to fall within 1 degree Fahrenheit of the recorded daily mean for cases where the daily mean was available, and seemed acceptable for imputation. For the minority of cases still missing a county mean temperature for a given date (43 of 1,329 days), the dataset-wide mean temperature for that date was used. For missing daily maximum or minimum data, the corresponding statewide mean value was imputed - this followed the mean temperature imputation process.  

* Not all counties had weather stations and thus some counties lacked temperature observations. In order to apply population weighting of temperature data, counties with unavailable data were assigned to have the same temperature data as a neighboring county as the same general longitude (e.g. Kings County, NY data was also assigned to Queens County, NY as Kings County (Brooklyn) is adjacent to Queens County (Queens)).  

* Census data was not available for 2018, so for county population weighting of temperature data, population estimates from 2017 were re-used. Based on comparison of 2015/16/17 county shifts, this should not introduce much bias in population weights, as New York counties had very stable population proportions (proportion of the total NY population living in a given county) in each of the three years where data was available.  

## Analyses Conducted and Results

This analysis largely focused on regression with ARMA errors, with spectral analysis indicating good regression coefficients for sine/cosine pairs. While NYISO daily electricity demand was the primary interest and yielded the better-performing model, a closely related ISONE model yielded fairly good results in its own right.

```{r}
# loading packages used in this analysis
library(astsa)
library(cowplot)
library(dplyr)
library(forecast)
library(ggplot2)
library(ggfortify) # use this with forecast package if using at all
library(MASS)
library(stringr)
library(tidyr)

# ensuring MASS::select() doesn't override dplyr::select()
select <- dplyr::select

# loading the data and filtering to pre-2019 observations
path.nyiso <- 
  "C:/Users/Duane/Documents/Academic/Villanova/5. Spring 19/Project Data/nyisoDY_all.csv" 
path.isone <- 
  "C:/Users/Duane/Documents/Academic/Villanova/5. Spring 19/Project Data/isoneDY_all.csv"

nyiso <- 
  read.csv(path.nyiso) %>%
  mutate(date = as.Date(date)) %>%
  filter(year < 2019)

isone <- 
  read.csv(path.isone) %>%
  mutate(date = as.Date(date)) %>%
  filter(year < 2019)

# quick glimpse of the datasets
#head(nyiso, 2) %>%
#  bind_rows(tail(nyiso, 2))
#head(isone, 2) %>%
#  bind_rows(tail(isone, 2))
```

# Detailed Analysis

## Exploratory Data Analysis

### NYISO data

```{r}
# setting some x-axis label and gridline defaults
monthly_x_setup <- 
  list(
    theme_ds2(),
    scale_x_date(date_breaks      ="3 months", 
                 date_minor_breaks="1 month",
                 date_labels      ="%b-%Y"),
    theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1),
          panel.grid.major.x=element_line(color="lightgrey", linetype=1),
          panel.grid.minor.x=element_line(color="lightgrey", linetype=1))
    )

# time series plot of daily demand and net generation
nyiso %>%
  select(date, demand.GWh, netGen.GWh) %>%
  gather(key="metric", value="value", -date) %>%
  ggplot(aes(x=date, y=value, color=metric)) +
  geom_line() +
  annotate("text", x=as.Date("2016-01-01"), y=520, label="Demand", 
           color=color_set8[1], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2015-06-01"), y=280, label="Net Generation", 
           color=color_set8[2], hjust = 0, size = 4.5) +
  labs(title="NYISO daily electricity demand and net generation",
       subtitle = "Demand - Net Generation = Imports",
       x="Date", y="Quantity of electrical power \n (gigawatt-hours)",
       caption="1 GWh = 9,090 Nissan Leaf engines at full capacity for 1 hour",
       color=NULL) +
  scale_color_manual(values=color_set8[1:2], guide=F) +
  monthly_x_setup
```

There seems to be a pretty clear seasonal component, with demand/net generation spiking primarily in the summer (July, August, September) and secondarily in winter (late December to late March). The greatest gap between demand and net generation occurs during this secondary increase. At least, this is the case when considering net generation as a percentage of demand; in absolute terms the discrepancies are fairly stable across months.

```{r}
# time series plot of daily demand and scaled daily temperature
ggplot() +
  geom_line(
    data = nyiso %>% 
           select(date, demand.GWh),
    aes(x=date, y=demand.GWh), color=color_set8[1]
    ) +
  geom_line(
    data = 
      nyiso %>%
      select(date, tempAvg.F, tempMax.F, tempMin.F) %>%
      mutate(tempAvg.F = tempAvg.F * 8,
             tempMax.F = tempMax.F * 8,
             tempMin.F = tempMin.F * 8) %>%
      gather(key="metric", value="value", -date),
    aes(x=date, y=value, color=metric), alpha=0.6
    ) +
  annotate("text", x=as.Date("2015-10-30"), y=180, label="Demand", 
           color=color_set8[1], hjust = 0.9, size = 4.5) +
  annotate("text", x=as.Date("2016-08-15"), y=180, label="Max. temp.", 
           color=color_set8[6], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2016-08-15"), y=130, label="Mean temp.", 
           color=color_set8[7], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2016-08-15"), y=80, label="Min. temp.", 
           color=color_set8[8], hjust = 0.5, size = 4.5) +
  labs(title="NYISO daily electricity demand and temperature summaries",
       x="Date", y="Electricity demand (gigawatt-hours)",
       color=NULL) +
  scale_color_manual(values=color_set8[c(7,6,8)], guide=F) +
  scale_y_continuous(sec.axis=sec_axis(~. / 8,  name="Temperature (F)")) +
  monthly_x_setup
```

The plot above seems to suggest a variable capturing "absolute average deviation from [roughly] 50F"*  may be a more useful variable for predicting daily electricity demand than, say, the daily mean temperature. Therefore, I'll create that variable (using just `tempAvg.F`; logically, there is strong correlation among max./mean/min. temperatures).

*The dataset mean daily-mean temperature is 53.96F, covering 01 Jul 2015 to 31 Dec 2018; I considered using this mean rather than 50F, but the regression model considered further down had almost the same $R^2_\text{adj}$ using 50F - about 0.923 using the dataset mean and about 0.919 using 50 - and the it's a relatively 'simple' interpretation. It's interesting such a "nice" number (admittedly close to the sample mean) should work so well.

```{r}
nyiso <- 
  nyiso %>%
  mutate(absTempAvgMinus50.F = abs(tempAvg.F - 50))
  
# showing max / mean / min temperatures are highly correlated
nyiso %>%
  select(tempMax.F, tempAvg.F, tempMin.F) %>%
  cor() %>%
  round(4)
```

```{r}
# evaluating the new variable in a schmancy new plot
secAxisBreaks <- seq(0, 50, 10)

nyiso %>%
  select(date, demand.GWh, absTempAvgMinus50.F) %>%
  mutate(absTempAvgMinus50.F = absTempAvgMinus50.F * 7 + mean(nyiso$demand.GWh)) %>%
  gather(key="metric", value="value", -date) %>%
  ggplot(aes(x=date, y=value, color=metric)) +
  geom_line() +
  annotate("text", x=as.Date("2016-10-01"), y=340, label="Demand", 
           color=color_set8[1], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2016-11-01"), y=720, label="Absolute temperature \n deviation from 50F", 
           color=color_set8[7], hjust = 0.5, size = 4.5) +
  labs(title="NYISO daily electricity demand and |mean temp. dist. from 50F|",
       x="Date", y="Electricity demand (gigawatt-hours)",
       color=NULL) +
  scale_color_manual(values=color_set8[c(7,1)], guide=F) +
  scale_y_continuous(sec.axis=sec_axis(~(. / 7 - mean(nyiso$demand.GWh)/7),
                                       breaks=secAxisBreaks,
                                       labels=secAxisBreaks,  
                                       name  ="Absolute temperature \n deviation from 50F")) +
  monthly_x_setup
```

This new variable seems to track relatively well with electricity demand - though I think it would only have good "real world" explanatory power if there really is something connecting "particularly hot or cold" days and electricity usage. An increase in air conditioning activity during hot days seems likely, but for very cold days I'm not sure an uptick in electric heating (either as a primary or supplemental heat source) carries as much plausibility - perhaps there is this in addition to an increase in time spent indoors (and thus increased electrical device use).

This is the first plot so far to make clear there is an unusually low observation in 2018, on November 12 - the previous day was missing quite a few hourly observations, and it may be that there was some issue with the data-recording process in this period. In other words, it seems like the measurement process, rather than the actual value for the metric, was unusual here.

```{r}
# considering electricity demand and economic activity index
nyiso %>%
  mutate(econIndex.NY = econIndex.NY * 4)%>%
  select(date, demand.GWh, econIndex.NY) %>%
  gather(key="metric", value="value", -date) %>%
  ggplot(aes(x=date, y=value, color=metric)) +
  geom_line() +
  annotate("text", x=as.Date("2016-10-01"), y=340, label="Demand", 
           color=color_set8[1], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2017-02-01"), y=550, label="Economic \n index", 
           color=color_set8[8], hjust = 0.5, size = 4.5) +
  labs(title="NYISO daily electricity demand and monthly economic activity index",
       x="Date", y="Electricity demand (gigawatt-hours)",
       color=NULL) +
  scale_color_manual(values=color_set8[c(1,8)], guide=F) +
  scale_y_continuous(sec.axis=sec_axis(~. / 4, 
                                       name  ="Economic activity index \n (100 = 2007 annual mean)")) +
  monthly_x_setup
```

I doubt the monthly economic activity index will provide much prediction utility - it's not granular enough to be of much use for daily data, and it appears to be monotonic - I checked this via `plot(nyiso$econIndex.NY, type="l")`. 

```{r, fig.width=9, fig.height=3.5}
# ACF and PCF plots of demand.GWh - with GGPlot2 styling
# default lags (aligns with monthly span reasonably well)
acfPlot <- 
  autoplot(acf(nyiso$demand.GWh, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(title="ACF and PACF for nyiso$demand.GWh") +
  theme_ds2()

pacfPlot <- 
  autoplot(pacf(nyiso$demand.GWh, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(title=expression("lag.max "%~~%" 31"), y="Partial ACF") +
  theme_ds2()

cowplot::plot_grid(acfPlot, pacfPlot, ncol=2)

# default lag.max=366 (aligns with annual span)
acfPlot <- 
  autoplot(acf(nyiso$demand.GWh, plot=F, lag.max=366)) +
  geom_hline(yintercept = 0) +
  labs(title="ACF and PACF for nyiso$demand.GWh") +
  theme_ds2()

pacfPlot <- 
  autoplot(pacf(nyiso$demand.GWh, plot=F, lag.max=366)) +
  geom_hline(yintercept = 0) +
  labs(title="lag.max=366", y="Partial ACF") +
  theme_ds2()

cowplot::plot_grid(acfPlot, pacfPlot, ncol=2)
```

The two sets of ACF and PCF plots clearly indicate the NYISO daily electricity demand data don't reflect a stationary process - this was generally established in the prior plots, but this set of plots also reflect it is not adequately summarized by a "pure" autoregressive or moving average process. We wouldn't expect that given the seasonal pattern in the data. 

The ACF 'peaks' in 7-unit increments in the first plot set would seem to indicate a weekly component, and the second plot set might reflect semi-annual and annual cycle peaks given the ACF behavior around (roughly) lags 183 and 365.

```{r}
# comparing actual and predicted demand (both from the original dataset)
tibble(
  date   = rep(nyiso$date[1:{nrow(nyiso)-1}], 2),
  metric = rep(c("demand.GWh", "predictedDemand.GWh"), each = {nrow(nyiso)-1}),
  value  = c(nyiso$demand.GWh[1:{nrow(nyiso)-1}], nyiso$dayAheadDemand.GWh[2:nrow(nyiso)])
  ) %>%
  ggplot(aes(x=date, y=value, color=metric)) +
  geom_line() +
  annotate("text", x=as.Date("2016-02-01"), y=550, label="Demand", 
           color=color_set8[1], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2017-02-01"), y=550, label="'Day ahead' \n prediction", 
           color=color_set8[5], hjust = 0.5, size = 4.5) +
  labs(title="NYISO daily electricity demand and aligned 'day ahead' demand",
       x="Date", y="Electricity demand (gigawatt-hours)",
       color=NULL) +
  scale_color_manual(values=color_set8[c(1,5)], guide=F) +
  monthly_x_setup 
```

The 'day ahead demand' data from the original dataset aligns pretty well with the actual electricity demand for each day.

```{r, fig.width=9.5, fig.height=3.5}
# comparing ccf for average temperature or absolute deviance from 50F for demand
par(mfrow=c(1,2))
ccf2(x=nyiso$tempAvg.F, y=nyiso$demand.GWh)
box(bty="7", col="lightgrey")

ccf2(x=nyiso$absTempAvgMinus50.F, y=nyiso$demand.GWh)
box(bty="7", col="lightgrey")
```

While the newly created "temp. distance from 50F" variable seems to be a much better predictor of the next day or two's electricity demand (the CCF values at right are almost twice that of the left plot), since the process isn't yet stationary and the distribution is so symmetrical about zero there doesn't seem to be much to make of this yet.

### ISONE data

```{r}
# time series plot of daily demand and net generation
isone %>%
  select(date, demand.GWh, netGen.GWh) %>%
  mutate(ximports.GWh = (demand.GWh - netGen.GWh)+250) %>%
  gather(key="metric", value="value", -date) %>%
  ggplot(aes(x=date, y=value, color=metric)) +
  geom_line() +
  annotate("text", x=as.Date("2016-02-01"), y=450, label="Demand", 
           color=color_set8[3], hjust = 0.5, size = 4.5) +
  annotate("text", x=as.Date("2016-02-01"), y=200, label="Net Generation", 
           color=color_set8[4], hjust = 0.5, size = 4.5) +
  labs(title="ISONE daily electricity demand and net generation",
       subtitle = "Demand - Net Generation = Imports (dark grey)",
       x="Date", y="Quantity of electrical power \n (gigawatt-hours)",
       color=NULL) +
  scale_color_manual(values=c(color_set8[3:4], "grey50"), guide=F) +
  scale_y_continuous(sec.axis=sec_axis(~. - 250, 
                                       name  ="Electric imports (GWh)")) +
  monthly_x_setup
```

Interestingly, the ISONE demand and net generation data follows a similar general pattern as the NYISO data (largest peaks in summer months with a secondary peak in winter months), though daily demand is roughly 100 GWh less in the New England states.

```{r, fig.width=9, fig.height=3.5}
# ACF and PCF plots of demand.GWh - with GGPlot2 styling
# default lags (aligns with monthly span reasonably well)
acfPlot <- 
  autoplot(acf(isone$demand.GWh, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(title="ACF and PACF for isone$demand.GWh") +
  theme_ds2()

pacfPlot <- 
  autoplot(pacf(isone$demand.GWh, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(title=expression("lag.max "%~~%" 31"), y="Partial ACF") +
  theme_ds2()

cowplot::plot_grid(acfPlot, pacfPlot, ncol=2)

# default lag.max=366 (aligns with annual span)
acfPlot <- 
  autoplot(acf(isone$demand.GWh, plot=F, lag.max=366)) +
  geom_hline(yintercept = 0) +
  labs(title="ACF and PACF for nyiso$demand.GWh") +
  theme_ds2()

pacfPlot <- 
  autoplot(pacf(isone$demand.GWh, plot=F, lag.max=366)) +
  geom_hline(yintercept = 0) +
  labs(title="lag.max=366", y="Partial ACF") +
  theme_ds2()

cowplot::plot_grid(acfPlot, pacfPlot, ncol=2)
```

The ISONE ACF and PACF plots look very, very similar to those for NYISO data.

## NYISO analysis

Because the series has such a clear waveform pattern, it seems reasonable to start by trying to identify key underlying frequencies.

### Spectral analysis

```{r, fig.height=3.2}
# spectral analysis
# creating the time series
meanCtrDemand.GWh <- nyiso$demand.GWh - mean(nyiso$demand.GWh)

nyisoDemand.GWh <- ts(meanCtrDemand.GWh, start=nyiso$date[1], frequency=365.25)

# computing and plotting the scaled periodograms
P = Mod(2*fft(nyisoDemand.GWh)/length(nyisoDemand.GWh))^2
Fr = 0:(length(nyisoDemand.GWh)-1)/length(nyisoDemand.GWh)

tibble(Fr, P) %>%
  # show just the first half since there's symmetry at Fr=0.5
  filter(Fr <= 0.5) %>%
  ggplot(aes(x=Fr %>% as.numeric(), y = P %>% as.numeric(), 
             color = P %>% as.numeric())
         ) +
  geom_line(color=color_set8[1]) +
  geom_point(alpha=0.9, size=3) +
  labs(title="nyiso$demand.GWh scaled periodogram",
       x="Frequency", y="Scaled periodogram") +
  scale_color_viridis_c(direction=-1, guide=F) +
  theme_ds2()
```

There are clearly some frequencies that are much more prominent than the rest, especially at low frequencies. The next plot more clearly illustrates that these align with once- or twice-yearly frequencies, which should correspond with the summer/winter peaks seen in the EDA plots. The highest-value frequency that also stands out seems to align (very roughly) with a twice-monthly frequency, which will also be considered.

```{r, fig.height=3.5}
# plot summarizing the "most important" frequencies
# first filter to only Frequencies <= 0.5 because of symmetry about 0.5
Fr.red <- Fr[Fr<=0.5]
P.red  <- P[Fr<=0.5]

fractionDat <- 
  tibble(
    Freq = as.character(fractions(Fr.red)) %>% 
           factor(levels=as.character(fractions(Fr.red))[order(P.red, decreasing=T)]),
    Pdgm = P.red
    ) %>%
  arrange(desc(Pdgm)) %>%
  head(10) %>%
# want the top 10 Freq fractions to have common denominator 1280
# need to scale 3rd (1/320 >> 4/1280), 5th (1/256 >> 5/1280), 6th (1/640 >> 2/1280)
#               8th (183/640 >> 366/1280), and 10th (3/640 >> 6/1280)
# requires converting Freq to character then 'resetting' Freq factor levels after
  mutate(
    Freq = as.character(Freq),
    Freq = if_else(Freq == "1/320", "4/1280",
              if_else(Freq == "1/256", "5/1280",
                 if_else(Freq == "1/640", "2/1280",
                    if_else(Freq == "183/640", "366/1280",
                       if_else(Freq == "3/640", "6/1280", Freq))))
              ),
    # returning to factor - the pasted c() string are the rescaled numerators
    Freq = factor(Freq, levels=paste(c(7,3,4,183,5,2,13,366,11,6),1280, sep="/"))
    )

fractionDat %>%  
  ggplot(aes(x=Freq, y=Pdgm)) +
  geom_col(fill=color_set8[1]) +
  annotate("text", x=4, y=2850, hjust=0, 
           label="Top 4 frequencies in annual terms:") +
  annotate("text", x=4, y=2500, hjust=0, 
           label=expression(omega*" = 7/1280"%~~%"0.00547 ; 2/365.25"%~~%"0.00548")) +
  annotate("text", x=4, y=2000, hjust=0, 
           label=expression(omega*" = 3/1280"%~~%"0.00234 ; 0.85/365.25"%~~%"0.00233")) +
  annotate("text", x=4, y=1750, hjust=0, 
           label=expression(omega*" = 4/1280"%~~%"0.00313 ; 1.14/365.25"%~~%"0.00312")) +
  annotate("text", x=4, y=1250, hjust=0, 
           label=expression(omega*" = 183/1280"%~~%"0.14297 ; 52.22/365.25"%~~%"0.14297")) +
  labs(title="Top 10 frequencies by scaled periodogram value",
       subtitle="nyisoDemand.GWh",
       x="Frequency", y="Scaled Periodogram") +
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1))
```

### Regression modelling - frequencies, temperatures, weekdays, months (plus ARMA errors)

The following model is a bit of a "kitchen sink" approach. It's worth noting that adding the 'absolute temperature deviance from 50F' variable moved the $R^2_\text{adj}$ of the 'penultimate' model from 0.6552 to 0.8196. The corresponding AIC change was from 12761.71 to 11933.98, respectively. From there, including the 'previous day's demand' variable (per Dr. Frey's suggestion) improved the $R^2_\text{adj}$ from 0.8196 to 0.9193 (and AIC from 11933.98 to 10895.85).

The 'once per 2 months' frequency (183/1280 above) didn't have statistically significant sine or cosine terms using either 52 (closest integer) or 60 ('2 months') out of 365.25. The quadratic time indicator was marginally statistically significant (*p*-value 0.056), so I kept it in the model.

It wasn't possible to fit all but one month indicator (or even all but five) in the model due to singularities, which seems odd but perhaps this is somehow connected to the sine/cosine frequency variables. I chose to not include month indicator variables - selectively including some months improved the model fit, but it seemed overly arbitrary.

\newpage

```{r}
# sin/cos variables based on class code example for Philly weather
# from 3/27 class (7th set of class R code, around line 206 in .R file)

nyiso2 <- 
  nyiso %>%
  mutate(
    # creating a time index, quadratic time term, weekday/month variables,
    # key frequency sine/cosine pairs, and absolute temp deviance from 50F
    dayIndex      = 1:nrow(nyiso),
    dayIndex2.ctr = (dayIndex - mean(dayIndex))^2,
    # need an indicator variable for each weekday and each month (except ref levels)
    # Sunday is the reference level of weekday
    weekday       = weekdays(date),
    isSun         = (weekday == "Sunday") %>% as.integer(),
    isMon         = (weekday == "Monday") %>% as.integer(),
    isTue         = (weekday == "Tuesday") %>% as.integer(),
    isWed         = (weekday == "Wednesday") %>% as.integer(),
    isThu         = (weekday == "Thursday") %>% as.integer(),
    isFri         = (weekday == "Friday") %>% as.integer(),
    isSat         = (weekday == "Saturday") %>% as.integer(),
    # wasn't able to incorporate month(s) into the model
    # January is the reference level of month
    month         = months(date),
    isJan         = (month == "January") %>% as.integer(),
    isFeb         = (month == "February") %>% as.integer(),
    isMar         = (month == "March") %>% as.integer(),
    isApr         = (month == "April") %>% as.integer(),
    isMay         = (month == "May") %>% as.integer(),
    isJun         = (month == "June") %>% as.integer(),
    isJul         = (month == "July") %>% as.integer(),
    isAug         = (month == "Aug") %>% as.integer(),
    isSep         = (month == "Sep") %>% as.integer(),
    isOct         = (month == "Oct") %>% as.integer(),
    isNov         = (month == "Nov") %>% as.integer(),
    isDec         = (month == "Dec") %>% as.integer(),
    isDecJanFeb   = isDec + isJan + isFeb,
    isMarAprMay   = isMar + isApr + isMay,
    isJunJulAug   = isJun + isJul + isAug,
    isSepOctNov   = isSep + isOct + isNov,
    prevDayDemand = lag(demand.GWh),
    sin.1xYr      = sin(2*pi*(dayIndex)*(1/365.25)),
    cos.1xYr      = cos(2*pi*(dayIndex)*(1/365.25)),
    sin.2xYr      = sin(2*pi*(dayIndex)*(2/365.25)),
    cos.2xYr      = cos(2*pi*(dayIndex)*(2/365.25)),
    # next 2 weren't stat. sig. using either 52 or 60
    sin.2Mo       = sin(2*pi*(dayIndex)*(52/365.25)),
    cos.2Mo       = cos(2*pi*(dayIndex)*(52/365.25)),
    absTempAvgMinus50.F = abs(tempAvg.F - 50)
    )

# fitting the model
nyisoDemandGWh.lm <- 
  lm(demand.GWh ~ dayIndex + dayIndex2.ctr + prevDayDemand +
                  isMon + isTue + isWed + isThu + isFri + isSat + 
                  sin.1xYr + cos.1xYr + sin.2xYr + cos.2xYr + 
                  sin.2Mo + cos.2Mo + absTempAvgMinus50.F,
                  data=nyiso2)

# no 'stargazing'
options(show.signif.stars = F)

#summary(nyisoDemandGWh.lm)

# sin/cos.2Mo terms aren't stat. sig. - updating the model
nyisoDemandGWh.lm <- update(nyisoDemandGWh.lm, 
                            .~. -sin.2Mo -cos.2Mo)

# summary of the 'final' model
summary(nyisoDemandGWh.lm)
```

```{r, fig.width=5, fig.height=5}
# ACF and PCF plots of demand.GWh - with GGPlot2 styling
acfPlot <- 
  autoplot(acf(nyisoDemandGWh.lm$residuals, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(subtitle="ACF & PACF for nyisoDemandGWh.lm$residuals") +
  theme_ds2()

pacfPlot <- 
  autoplot(pacf(nyisoDemandGWh.lm$residuals, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(title=NULL, y="Partial ACF") +
  theme_ds2()

cowplot::plot_grid(acfPlot, pacfPlot, ncol=1)
```

This seems like a prime candidate for fitting an ARMA model to the residuals - ARMA(1,1) may work based on the above.

```{r}
# determining a good ARMA model for errors using the AIC matrix approach
uprLim = 5
aicMat = matrix(double((uprLim+1)^2), uprLim+1, uprLim+1)
for (i in 0:uprLim){
  for (j in 0:uprLim){
    aicMat[i+1,j+1] = sarima(nyisoDemandGWh.lm$residuals, i, 0, j,
                              details = F)$AIC
    rownames(aicMat) <- paste0("p:", 0:uprLim)
    colnames(aicMat) <- paste0("q:", 0:uprLim)
    }
  }
# identify the row, column index of the minimum value
which(aicMat == min(aicMat), arr.ind = T)

aicMat %>% round(3)
```

While ARMA(5,1) has the "best" AIC value, ARMA(0,1) a.k.a. MA(1) comes close here.

```{r}
sarima(nyisoDemandGWh.lm$residuals, p=0, d=0, q=1)
```

Excepting the worrisome skewedness in the tails of the Normal Q-Q plot (indicating heavy tails, especially at right), the diagnostic plots look quite good. The mean value of the process is very, very plausibly zero (*p*-value = 0.880), and the MA(1) component is very statistically significant.

### Predicting from the model

The 'in-model' data ends at the very end of 2018 (31 Dec 2018) but there's data up to mid-February 2019, so predicting early 2019's demand (January through 14 Feb 2019) and comparing to 'the real thing' is pretty easy. Given the Ljung-Box diagnostic plot above, I suspect the predictions after about a week may stray fairly far from the observed values.

```{r}
# decent online reference - just tucking this away in the comments
# https://otexts.com/fpp2/

# loading the data, filtering to Jan through 14 Feb 2019 observations, computing needed covariates
path.nyiso <- 
  "C:/Users/Duane/Documents/Academic/Villanova/5. Spring 19/Project Data/nyisoDY_all.csv" 

nyisoEarly2019 <- 
  read.csv(path.nyiso) %>%
  mutate(date = as.Date(date)) %>%
  filter(year == 2019, date <= as.Date("2019-02-14"))

nyisoEarly2019 <- 
  nyisoEarly2019 %>%
  mutate(
    # creating only the variables needed for forecasting
    intercept     = 1,
    dayIndex      = (nrow(nyiso2)+1):(nrow(nyiso2) + nrow(nyisoEarly2019)),
    dayIndex2.ctr = (dayIndex - mean(dayIndex))^2,
    # need an indicator variable for each weekday and each month (except ref levels)
    # Sunday is the reference level of weekday
    weekday       = weekdays(date),
    isSun         = (weekday == "Sunday") %>% as.integer(),
    isMon         = (weekday == "Monday") %>% as.integer(),
    isTue         = (weekday == "Tuesday") %>% as.integer(),
    isWed         = (weekday == "Wednesday") %>% as.integer(),
    isThu         = (weekday == "Thursday") %>% as.integer(),
    isFri         = (weekday == "Friday") %>% as.integer(),
    isSat         = (weekday == "Saturday") %>% as.integer(),
    month         = months(date),
    # first entry will be NA for prevDayDemand - need to carry in 31 Dec 2018 
    prevDayDemand = if_else(dayIndex==(nrow(nyiso2)+1), 
                            nyiso2$demand.GWh[nrow(nyiso2)],
                            lag(demand.GWh)),
    sin.1xYr      = sin(2*pi*(dayIndex)*(1/365.25)),
    cos.1xYr      = cos(2*pi*(dayIndex)*(1/365.25)),
    sin.2xYr      = sin(2*pi*(dayIndex)*(2/365.25)),
    cos.2xYr      = cos(2*pi*(dayIndex)*(2/365.25)),
    absTempAvgMinus50.F = abs(tempAvg.F - 50)
    )

betaHats <- coef(nyisoDemandGWh.lm)

# column names for model covariates from the regression component
modelCovariates <- 
  (summary(nyisoDemandGWh.lm)$terms %>% as.character())[3] %>%
  strsplit(split = "\\+") %>% 
  unlist() %>%
  str_trim()

predXMat <- 
  nyisoEarly2019 %>%
  select(intercept, modelCovariates) %>%
  as.matrix()

lmPred    <- predXMat %*% betaHats
```

```{r, fig.show = "hide"}
errorPred <- sarima.for(nyisoDemandGWh.lm$residuals,
                        n.ahead = nrow(nyisoEarly2019),
                        p=0, d=0, q=1)
```

```{r, fig.height=4}
modelPred <- lmPred + errorPred$pred

nyisoEarly2019 <- 
  nyisoEarly2019 %>%
  mutate(modEst = modelPred %>% as.numeric())

# plotting the results: actual vs. fitted "in-model" values plus predictions
nyiso.demandAllDat <- 
  nyiso2 %>%
  # don't have 'day 1' estimate due to missing prevDayDemand
  mutate(modEst = c(NA, unname(nyisoDemandGWh.lm$fitted.values))) %>%
  full_join(nyisoEarly2019) %>%
  mutate(modelResid = demand.GWh - modEst)
  
nyiso.demandAllPlotDat <- 
  nyiso.demandAllDat %>%
  select(date, demand.GWh, modEst) %>%
  gather(key="metric", value="value", -date) %>%
  mutate(qqch = if_else(metric == "demand.GWh" & date <= as.Date("2018-12-31"),
                         "Obs., in-sample",
                   if_else(metric == "demand.GWh" & date > as.Date("2018-12-31"),
                           "Obs., out-of-sample",
                     if_else(metric == "modEst" & date <= as.Date("2018-12-31"),
                             "Model, in-sample", "Model, out-of-sample")))
         )

# full view
ggplot(nyiso.demandAllPlotDat, aes(x=date, y=value)) +
  geom_line(data=nyiso.demandAllPlotDat %>% filter(grepl("Obs.", qqch)),
            aes(color=qqch)) +
  geom_point(data=nyiso.demandAllPlotDat %>% filter(grepl("Model", qqch), 
                                                    date >= as.Date("2015-07-02")),
             aes(fill=qqch), shape=21,
             alpha=0.8) + 
  labs(title="NYISO demand.GWh observed vs model fit",
       subtitle="1 Jul 2015 through 14 Feb 2019",
       x="Date", y="Electrical power demand \n (gigawatt-hours)",
       caption="No model estimate for 1 Jul 2015 (no 'previous day demand')",
       color=NULL, fill=NULL) +
  scale_color_manual(values=color_set8[c(1,7)]) +
  scale_fill_manual(values=color_set8[c(2,6)]) +
  monthly_x_setup +
  theme(legend.direction = "vertical", 
        legend.margin = margin(c(0,0,0,0)),
        legend.position = "top")

# focusing on Oct 2018 forward
ggplot(nyiso.demandAllPlotDat,
       aes(x=date, y=value)) +
  geom_line(data=nyiso.demandAllPlotDat %>% filter(grepl("Obs.", qqch),
                                                   date >= as.Date("2018-10-01")),
            aes(color=qqch)) +
  geom_point(data=nyiso.demandAllPlotDat %>% filter(grepl("Model", qqch),
                                                    date >= as.Date("2018-10-01")),
             aes(fill=qqch), shape=21,
             alpha=0.8) + 
  labs(title="NYISO demand.GWh observed vs model fit",
       subtitle="1 Oct 2018 through 14 Feb 2019",
       x="Date", y="Electrical power demand \n (gigawatt-hours)",
       color=NULL, fill=NULL) +
  scale_color_manual(values=color_set8[c(1,7)]) +
  scale_fill_manual(values=color_set8[c(2,6)]) +
  monthly_x_setup +
  # need to revise the the breaks in the scale_x_date part of monthly_x_setup 
  scale_x_date(date_breaks      ="1 month",
               date_minor_breaks="1 month",
               date_labels      ="%b-%Y") +
  theme(legend.direction = "vertical", 
        legend.margin = margin(c(0,0,0,0)),
        legend.position = "top")
```

Not bad! It doesn't look as close as the in-dataset "day ahead demand" variable (when aligned with the appropriate day), but the model seems reasonable. Perhaps I was overly concerned about the model's residual-estimating performance 1+ weeks out.

Let's compare the root-mean-square error (RMSE) for the model vs. 'aligned day-ahead demand' and take a quick look at where the model misses most:

```{r}
# in- vs out-of-sample RMSE for model vs. 'aligned day-ahead demand'
#   'aligned day-ahead demand' might technically be considered to be all in-sample
# to allow for apples-to-apples comparison,
# need to compare 02 Jul 2015 through 14 Feb 2019 
#   (not 01 Jul 2015 - missing prevDayDemand for the model)

inSampRMSE <-
  nyiso.demandAllDat %>%
  mutate(alignedDayAheadDemand.GWh = lag(dayAheadDemand.GWh)) %>% 
  filter(date >= as.Date("2015-07-02"),
         date <= as.Date("2018-12-31")) %>%
  mutate(demandVSalignedDayAheadDemand = demand.GWh - alignedDayAheadDemand.GWh)
    
inSampRMSE <- 
  tibble(source = c("model", "alignedDayAheadDemand"),
         where  = "in-sample",
         RMSE   = c(sqrt(sum(inSampRMSE$modelResid^2)/nrow(inSampRMSE)),
                    sqrt(sum(inSampRMSE$demandVSalignedDayAheadDemand^2)/nrow(inSampRMSE))
                    ))

outSampRMSE <-
  nyiso.demandAllDat %>%
  mutate(alignedDayAheadDemand.GWh = lag(dayAheadDemand.GWh)) %>% 
  filter(date > as.Date("2018-12-31"),
         date <= as.Date("2019-02-14")) %>%
  mutate(demandVSalignedDayAheadDemand = demand.GWh - alignedDayAheadDemand.GWh)
    
outSampRMSE <- 
  tibble(source = c("model", "alignedDayAheadDemand"),
         where  = "out-of-sample",
         RMSE   = c(sqrt(sum(outSampRMSE$modelResid^2)/nrow(outSampRMSE)),
                    sqrt(sum(outSampRMSE$demandVSalignedDayAheadDemand^2)/nrow(outSampRMSE))
                    ))  

inSampRMSE %>%
  full_join(outSampRMSE, by=c("source", "where", "RMSE"))
```

Very interesting - the model has much lower RMSE both in- and out-of-sample vs. the 'aligned day-ahead demand' metric in the dataset. 'Out-of-sample' RMSE may be lower in both cases since there are much fewer observations (and thus less 'misses' to accumulate) - though I'd think dividng by the number of cases would adjust for this. Perhaps normalized RMSE (dividing the above results by the sample-appropriate mean of `demand.GWh`) would be better, but for now I'll stick with the above as a relative comparison.

```{r}
# checking residuals
nyiso.demandAllDat %>% 
  mutate(absResid = abs(modelResid)) %>%
  arrange(desc(absResid)) %>%
  mutate(date = format(date, format="%d %b %Y")) %>%
  select(date, prevDayDemand, weekday, demand.GWh, modEst, modelResid) %>%
  mutate_if(is.numeric, round, digits=1) %>%
  head(10)
```

Unsurprisingly, two of the model's worst 'misses' (largest absolute residuals) occur on 1-2 July 2018, days which had considerable missingness (and thus imputation). I checked values of the other covariates for these cases, but there didn't seem to be anything extraordinary - I believe the model was simply overly-reliant on the `prevDayDemand` values.

\newpage

## ISONE analysis

Since the ISONE `demand.GWh` data was so similar (in form if not magnitude) to the NYISO data, I'd expect very similar results for the spectral analysis. Unfortunately there isn't temperature data available now, so overall model performance will likely suffer accordingly.

### Spectral analysis

```{r, fig.height=3.2}
# spectral analysis

# reminder: isone is filtered to 01 Jul 2015 to 31 Dec 2018

# creating the time series
meanCtrDemand.GWh <- isone$demand.GWh - mean(isone$demand.GWh)

isoneDemand.GWh <- ts(meanCtrDemand.GWh, start=isone$date[1], frequency=365.25)

# computing and plotting the scaled periodograms
P = Mod(2*fft(isoneDemand.GWh)/length(isoneDemand.GWh))^2
Fr = 0:(length(isoneDemand.GWh)-1)/length(isoneDemand.GWh)

tibble(Fr, P) %>%
  # show just the first half since there's symmetry at Fr=0.5
  filter(Fr <= 0.5) %>%
  ggplot(aes(x=Fr %>% as.numeric(), y = P %>% as.numeric(), 
             color = P %>% as.numeric())
         ) +
  geom_line(color=color_set8[3]) +
  geom_point(alpha=0.9, size=3) +
  labs(title="isone$demand.GWh scaled periodogram",
       x="Frequency", y="Scaled periodogram") +
  scale_color_viridis_c(direction=-1, guide=F) +
  theme_ds2()
```

Interestingly the very-top frequencies are similar to those of NYISO demand, but there is less uncertainty for the very low-frequency value(s).

```{r, fig.height=3.5}
# plot summarizing the "most important" frequencies
# first filter to only Frequencies <= 0.5 because of symmetry about 0.5
Fr.red <- Fr[Fr<=0.5]
P.red  <- P[Fr<=0.5]

fractionDat <- 
  tibble(
    Freq = as.character(fractions(Fr.red)) %>% 
           factor(levels=as.character(fractions(Fr.red))[order(P.red, decreasing=T)]),
    Pdgm = P.red
    ) %>%
  arrange(desc(Pdgm)) %>%
  head(10) %>%
# want the top 10 Freq fractions to have common denominator 1280
# interestingly, only 10th differs from NYISO top 10 (not exact same order/Pdgm)
# need to scale 6th (1/256 >> 5/1280), 7th (3/640 >> 6/1280), 8th (183/640 >> 366/1280),
#               9th (1/320 >> 4/1280), and 10th (3/320 >> 12/1280)
# requires converting Freq to character then 'resetting' Freq factor levels after
  mutate(
    Freq = as.character(Freq),
    Freq = if_else(Freq == "1/256", "5/1280" ,
              if_else(Freq == "3/640", "6/1280",
                 if_else(Freq == "183/640", "366/1280",
                    if_else(Freq == "1/320", "4/1280",
                       if_else(Freq == "3/320", "12/1280", Freq))))
              ),
    # returning to factor - the pasted c() string are the rescaled numerators
    Freq = factor(Freq, levels=paste(c(7,183,3,11,13,5,6,366,4,12),1280, sep="/"))
    )

fractionDat %>%  
  ggplot(aes(x=Freq, y=Pdgm)) +
  geom_col(fill=color_set8[3]) +
  annotate("text", x=4, y=2000, hjust=0, 
           label="Top 3 frequencies in annual terms:") +
  annotate("text", x=4, y=1700, hjust=0, 
           label=expression(omega*" = 7/1280"%~~%"0.00547 ; 2/365.25"%~~%"0.00548")) +
  annotate("text", x=4, y=1400, hjust=0, 
           label=expression(omega*" = 183/1280"%~~%"0.14297 ; 52.22/365.25"%~~%"0.14297")) +
  annotate("text", x=4, y=1100, hjust=0, 
           label=expression(omega*" = 3/1280"%~~%"0.00234 ; 0.85/365.25"%~~%"0.00233")) +
  labs(title="Top 10 frequencies by scaled periodogram value",
       subtitle="isoneDemand.GWh",
       x="Frequency", y="Scaled Periodogram") +
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1))
```

Some quick takeaways:  

* Once more, the 'once-per-year' is by far the most prominent frequency detected, though there are fewer 'accompanying' frequencies around this compared to the NYISO demand data.  

* The (approximately) 'once every two months' frequency appears again, though once more it is quite low relative to the 'top' frequency.  

* NYISO and ISONE demand share 9 of the same 10 'top' frequencies, only differing in the 'right tail' of the set (NYISO has 2/1280 as its #6 frequency, ISONE has 12/1280 as its #10 frequency). The order and relative magnitude of the shared top frequencies differ, though 7/1280 is far and away tops for both series, 3/1280 is top-3 for both, and 183/1280 is top-4 for both.   

### Regression modelling - frequencies, temperatures, weekdays, months (plus ARMA errors)

This will adhere as closely as possible to the NYISO model, though it lacks temperature data and the retained fundamental frequencies (sine/cosine covariates) may differ based on statistical significance. The quadratic time indicator has a fairly high *p*-value (about 0.3) and so was dropped.

I retained the time indicator variable despite its high *p*-value (about 0.23), as it seems fundamental to a time series regression model. 

The coefficients are understandably different than for the NYISO demand model, since here we cannot condition on absolute temperature deviation from 50F. It seems somewhat that the indicator variable `isSat` is negative, indicating that (adjusting for all other variables in the model) a typical Saturday would be expected to have lower electricity demand than for a typical Sunday (the reference level for weekday) - perhaps New England just really, really enjoys watching the Patriots play.

```{r}
# sin/cos variables based on class code example for Philly weather
# from 3/27 class (7th set of class R code, around line 206 in .R file)

isone2 <- 
  isone %>%
  mutate(
    # creating a time index, quadratic time term, weekday/month variables,
    # and key frequency sine/cosine pairs
    # dayIndex and dayIndex2.ctr have greatest p-vals (0.22-0.30) in first model
    dayIndex      = 1:nrow(isone),
    dayIndex2.ctr = (dayIndex - mean(dayIndex))^2,
    # need an indicator variable for each weekday and each month (except ref levels)
    # Sunday is the reference level of weekday
    weekday       = weekdays(date),
    isSun         = (weekday == "Sunday") %>% as.integer(),
    isMon         = (weekday == "Monday") %>% as.integer(),
    isTue         = (weekday == "Tuesday") %>% as.integer(),
    isWed         = (weekday == "Wednesday") %>% as.integer(),
    isThu         = (weekday == "Thursday") %>% as.integer(),
    isFri         = (weekday == "Friday") %>% as.integer(),
    isSat         = (weekday == "Saturday") %>% as.integer(),
    month         = months(date),
    prevDayDemand = lag(demand.GWh),
    sin.1xYr      = sin(2*pi*(dayIndex)*(1/365.25)),
    cos.1xYr      = cos(2*pi*(dayIndex)*(1/365.25)),
    sin.2xYr      = sin(2*pi*(dayIndex)*(2/365.25)),
    cos.2xYr      = cos(2*pi*(dayIndex)*(2/365.25)),
    # 
    sin.2Mo       = sin(2*pi*(dayIndex)*(52/365.25)),
    cos.2Mo       = cos(2*pi*(dayIndex)*(52/365.25))
    )

# fitting the model
isoneDemandGWh.lm <- 
  lm(demand.GWh ~ dayIndex + dayIndex2.ctr + prevDayDemand +
                  isMon + isTue + isWed + isThu + isFri + isSat + 
                  sin.1xYr + cos.1xYr + sin.2xYr + cos.2xYr + 
                  sin.2Mo + cos.2Mo,
                  data=isone2)


#summary(isoneDemandGWh.lm)

# sin/cos.2Mo terms aren't stat. sig. - updating the model
isoneDemandGWh.lm <- update(isoneDemandGWh.lm, 
                            .~. -dayIndex2.ctr -sin.2Mo -cos.2Mo)

# summary of the 'final' model
summary(isoneDemandGWh.lm)
```

```{r, fig.width=5, fig.height=5}
# ACF and PCF plots of demand.GWh - with GGPlot2 styling
acfPlot <- 
  autoplot(acf(isoneDemandGWh.lm$residuals, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(subtitle="ACF & PACF for isoneDemandGWh.lm$residuals") +
  theme_ds2()

pacfPlot <- 
  autoplot(pacf(isoneDemandGWh.lm$residuals, plot=F)) +
  geom_hline(yintercept = 0) +
  labs(title=NULL, y="Partial ACF") +
  theme_ds2()

cowplot::plot_grid(acfPlot, pacfPlot, ncol=1)
```

While ARMA(1,1) looked like a possible candidate for NYISO demand model residuals (and MA(1) was the final selection), here a slightly more complicated model might be called for.

```{r}
# determining a good ARMA model for errors using the AIC matrix approach
uprLim = 5
aicMat = matrix(double((uprLim+1)^2), uprLim+1, uprLim+1)
for (i in 0:uprLim){
  for (j in 0:uprLim){
    aicMat[i+1,j+1] = sarima(isoneDemandGWh.lm$residuals, i, 0, j,
                              details = F)$AIC
    rownames(aicMat) <- paste0("p:", 0:uprLim)
    colnames(aicMat) <- paste0("q:", 0:uprLim)
    }
  }
# identify the row, column index of the minimum value
which(aicMat == min(aicMat), arr.ind = T)

aicMat %>% round(3)
```

As with NYISO model residuals, a fairly complicated process (ARMA(5,5)) is 'best', but a much simpler alternative (here, ARMA(2,1)) is quite close.

```{r}
sarima(isoneDemandGWh.lm$residuals, p=2, d=0, q=1)
```

Once more, with feeling: the ISONE model's diagnostics are similar to those of NYISO data, though here the left tail of the Q-Q norm plot seems heavier and the model (ARMA(2,1)).

### Predicting from the model

The 'in-model' data ends at the very end of 2018 (31 Dec 2018) but there's data up to mid-February 2019, so predicting early 2019's demand (January through 14 Feb 2019) and comparing to 'the real thing' is pretty easy. Given the Ljung-Box diagnostic plot above, I suspect the predictions after about a week may stray fairly far from the observed values.

```{r}
# decent online reference - just tucking this away in the comments
# https://otexts.com/fpp2/

# loading the data, filtering to Jan through 14 Feb 2019 observations, computing needed covariates
path.isone <- 
  "C:/Users/Duane/Documents/Academic/Villanova/5. Spring 19/Project Data/isoneDY_all.csv" 

isoneEarly2019 <- 
  read.csv(path.isone) %>%
  mutate(date = as.Date(date)) %>%
  filter(year == 2019, date <= as.Date("2019-02-14"))

isoneEarly2019 <- 
  isoneEarly2019 %>%
  mutate(
    # creating only the variables needed for forecasting
    intercept     = 1,
    dayIndex      = (nrow(isone2)+1):(nrow(isone2) + nrow(isoneEarly2019)),
    # need an indicator variable for each weekday and each month (except ref levels)
    # Sunday is the reference level of weekday
    weekday       = weekdays(date),
    isSun         = (weekday == "Sunday") %>% as.integer(),
    isMon         = (weekday == "Monday") %>% as.integer(),
    isTue         = (weekday == "Tuesday") %>% as.integer(),
    isWed         = (weekday == "Wednesday") %>% as.integer(),
    isThu         = (weekday == "Thursday") %>% as.integer(),
    isFri         = (weekday == "Friday") %>% as.integer(),
    isSat         = (weekday == "Saturday") %>% as.integer(),
    month         = months(date),
    # first entry will be NA for prevDayDemand - need to carry in 31 Dec 2018 
    prevDayDemand = if_else(dayIndex==(nrow(isone2)+1), 
                            isone2$demand.GWh[nrow(isone2)],
                            lag(demand.GWh)),
    sin.1xYr      = sin(2*pi*(dayIndex)*(1/365.25)),
    cos.1xYr      = cos(2*pi*(dayIndex)*(1/365.25)),
    sin.2xYr      = sin(2*pi*(dayIndex)*(2/365.25)),
    cos.2xYr      = cos(2*pi*(dayIndex)*(2/365.25))
    )

betaHats <- coef(isoneDemandGWh.lm)

# column names for model covariates from the regression component
modelCovariates <- 
  (summary(isoneDemandGWh.lm)$terms %>% as.character())[3] %>%
  strsplit(split = "\\+") %>% 
  unlist() %>%
  str_trim()

predXMat <- 
  isoneEarly2019 %>%
  select(intercept, modelCovariates) %>%
  as.matrix()

lmPred    <- predXMat %*% betaHats
```

```{r, fig.show = "hide"}
errorPred <- sarima.for(isoneDemandGWh.lm$residuals,
                        n.ahead = nrow(isoneEarly2019),
                        p=2, d=0, q=1)
```

```{r, fig.height=4}
modelPred <- lmPred + errorPred$pred

isoneEarly2019 <- 
  isoneEarly2019 %>%
  mutate(modEst = modelPred %>% as.numeric())

# plotting the results: actual vs. fitted "in-model" values plus predictions
isone.demandAllDat <- 
  isone2 %>%
  # don't have 'day 1' estimate due to missing prevDayDemand
  mutate(modEst = c(NA, unname(isoneDemandGWh.lm$fitted.values))) %>%
  full_join(isoneEarly2019) %>%
  mutate(modelResid = demand.GWh - modEst)
  
isone.demandAllPlotDat <- 
  isone.demandAllDat %>%
  select(date, demand.GWh, modEst) %>%
  gather(key="metric", value="value", -date) %>%
  mutate(qqch = if_else(metric == "demand.GWh" & date <= as.Date("2018-12-31"),
                         "Obs., in-sample",
                   if_else(metric == "demand.GWh" & date > as.Date("2018-12-31"),
                           "Obs., out-of-sample",
                     if_else(metric == "modEst" & date <= as.Date("2018-12-31"),
                             "Model, in-sample", "Model, out-of-sample")))
         )

# full view
ggplot(isone.demandAllPlotDat, aes(x=date, y=value)) +
  geom_line(data=isone.demandAllPlotDat %>% filter(grepl("Obs.", qqch)),
            aes(color=qqch)) +
  geom_point(data=isone.demandAllPlotDat %>% filter(grepl("Model", qqch), 
                                                    date >= as.Date("2015-07-02")),
             aes(fill=qqch), shape=21,
             alpha=0.8) + 
  labs(title="ISONE demand.GWh observed vs model fit",
       subtitle="1 Jul 2015 through 14 Feb 2019",
       x="Date", y="Electrical power demand \n (gigawatt-hours)",
       caption="No model estimate for 1 Jul 2015 (no 'previous day demand')",
       color=NULL, fill=NULL) +
  scale_color_manual(values=color_set8[c(3,7)]) +
  scale_fill_manual(values=color_set8[c(4,6)]) +
  monthly_x_setup +
  theme(legend.direction = "vertical", 
        legend.margin = margin(c(0,0,0,0)),
        legend.position = "top")

# focusing on Oct 2018 forward
ggplot(isone.demandAllPlotDat,
       aes(x=date, y=value)) +
  geom_line(data=isone.demandAllPlotDat %>% filter(grepl("Obs.", qqch),
                                                   date >= as.Date("2018-10-01")),
            aes(color=qqch)) +
  geom_point(data=isone.demandAllPlotDat %>% filter(grepl("Model", qqch),
                                                    date >= as.Date("2018-10-01")),
             aes(fill=qqch), shape=21,
             alpha=0.8) + 
  labs(title="ISONE demand.GWh observed vs model fit",
       subtitle="1 Oct 2018 through 14 Feb 2019",
       x="Date", y="Electrical power demand \n (gigawatt-hours)",
       color=NULL, fill=NULL) +
  scale_color_manual(values=color_set8[c(3,7)]) +
  scale_fill_manual(values=color_set8[c(4,6)]) +
  monthly_x_setup +
  # need to revise the the breaks in the scale_x_date part of monthly_x_setup 
  scale_x_date(date_breaks      ="1 month",
               date_minor_breaks="1 month",
               date_labels      ="%b-%Y") +
  theme(legend.direction = "vertical", 
        legend.margin = margin(c(0,0,0,0)),
        legend.position = "top")
```

The model seems to fit the data fairly well, and predict reasonably well, but it seems to predict less well more quickly than does the NYISO demand model.

```{r}
# in- vs out-of-sample RMSE for model vs. 'aligned day-ahead demand'
#   'aligned day-ahead demand' might technically be considered to be all in-sample
# to allow for apples-to-apples comparison,
# need to compare 02 Jul 2015 through 14 Feb 2019 
#   (not 01 Jul 2015 - missing prevDayDemand for the model)

inSampRMSE <-
  isone.demandAllDat %>%
  mutate(alignedDayAheadDemand.GWh = lag(dayAheadDemand.GWh)) %>% 
  filter(date >= as.Date("2015-07-02"),
         date <= as.Date("2018-12-31")) %>%
  mutate(demandVSalignedDayAheadDemand = demand.GWh - alignedDayAheadDemand.GWh)
    
inSampRMSE <- 
  tibble(source = c("model", "alignedDayAheadDemand"),
         where  = "in-sample",
         RMSE   = c(sqrt(sum(inSampRMSE$modelResid^2)/nrow(inSampRMSE)),
                    sqrt(sum(inSampRMSE$demandVSalignedDayAheadDemand^2)/nrow(inSampRMSE))
                    ))

outSampRMSE <-
  isone.demandAllDat %>%
  mutate(alignedDayAheadDemand.GWh = lag(dayAheadDemand.GWh)) %>% 
  filter(date > as.Date("2018-12-31"),
         date <= as.Date("2019-02-14")) %>%
  mutate(demandVSalignedDayAheadDemand = demand.GWh - alignedDayAheadDemand.GWh)
    
outSampRMSE <- 
  tibble(source = c("model", "alignedDayAheadDemand"),
         where  = "out-of-sample",
         RMSE   = c(sqrt(sum(outSampRMSE$modelResid^2)/nrow(outSampRMSE)),
                    sqrt(sum(outSampRMSE$demandVSalignedDayAheadDemand^2)/nrow(outSampRMSE))
                    ))  

inSampRMSE %>%
  full_join(outSampRMSE, by=c("source", "where", "RMSE"))
```

The model seems to outperform the 'aligned day-ahead demand' from the ISONE dataset, as did the NYISO model previously.

```{r}
# checking residuals
isone.demandAllDat %>% 
  mutate(absResid = abs(modelResid)) %>%
  arrange(desc(absResid)) %>%
  mutate(date = format(date, format="%d %b %Y")) %>%
  select(date, prevDayDemand, weekday, demand.GWh, modEst, modelResid) %>%
  mutate_if(is.numeric, round, digits=1) %>%
  head(10)
```

The ISONE demand model has larger absolute residuals in its 'top 10 misses' set compared to the NYISO data, with 7 Jul 2018 a relatively large 'miss'. It seems one more that `prevDayDemand` is largely involved here.

# Conclusion

This was an enjoyable exploration of modeling time series data, and it seems that with just a few variables and a healthy dose of data formatting and R one can model 'well-behaved' electricity demand data without too much trouble.

# Ancillary analysis considerations: Spectral analysis of `netGen.GWh`

Unfortunately I ran out of time to conduct more extensive analyses, but some ideas for extending this analysis are:

* Including more recent data and observing the results, including perhaps truly predicting future observations and seeing how the model fares  

* Bringing in temperature data for the ISONE dataset and making a more direct comparison between NYISO and ISONE models  

* Analyzing `netGen.GWh`  

* Analyzing hourly-level data (which might require more granular temperature data)  

* Finding more useful/less arbitrary covariates (e.g. the 'degree heating days' idea Dr. Frey mentioned in our first meeting, or separate 'divergence from 50F' indicators for 'above 50F' and 'below 50F' Dr. Frey mentioned in the presentation)  

* Checking how energy demand compares vs. the model on certain specific dates (e.g. major holidays or events such as the Super Bowl)  
